{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f9784ab",
   "metadata": {},
   "source": [
    "# GO TO FILE FOR FINAL EXAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3333ec82",
   "metadata": {},
   "source": [
    "## Importing the Packges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b8e9ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, plot_roc_curve, roc_auc_score, roc_curve, auc, RocCurveDisplay, PrecisionRecallDisplay, precision_recall_curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ae24aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "np.random_seed = random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d2fd10",
   "metadata": {},
   "source": [
    "## IMPORTING FILE(CSV)\n",
    "\n",
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dafff032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v=pd.read_csv('smoke_detection_iot.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b6349097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UTC</th>\n",
       "      <th>Temperature[C]</th>\n",
       "      <th>Humidity[%]</th>\n",
       "      <th>TVOC[ppb]</th>\n",
       "      <th>eCO2[ppm]</th>\n",
       "      <th>Raw H2</th>\n",
       "      <th>Raw Ethanol</th>\n",
       "      <th>Pressure[hPa]</th>\n",
       "      <th>PM1.0</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>NC0.5</th>\n",
       "      <th>NC1.0</th>\n",
       "      <th>NC2.5</th>\n",
       "      <th>CNT</th>\n",
       "      <th>Fire Alarm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1654733331</td>\n",
       "      <td>20.000</td>\n",
       "      <td>57.36</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12306</td>\n",
       "      <td>18520</td>\n",
       "      <td>939.735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1654733332</td>\n",
       "      <td>20.015</td>\n",
       "      <td>56.67</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12345</td>\n",
       "      <td>18651</td>\n",
       "      <td>939.744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1654733333</td>\n",
       "      <td>20.029</td>\n",
       "      <td>55.96</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12374</td>\n",
       "      <td>18764</td>\n",
       "      <td>939.738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1654733334</td>\n",
       "      <td>20.044</td>\n",
       "      <td>55.28</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12390</td>\n",
       "      <td>18849</td>\n",
       "      <td>939.736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1654733335</td>\n",
       "      <td>20.059</td>\n",
       "      <td>54.69</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12403</td>\n",
       "      <td>18921</td>\n",
       "      <td>939.744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1654733336</td>\n",
       "      <td>20.073</td>\n",
       "      <td>54.12</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12419</td>\n",
       "      <td>18998</td>\n",
       "      <td>939.725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1654733337</td>\n",
       "      <td>20.088</td>\n",
       "      <td>53.61</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12432</td>\n",
       "      <td>19058</td>\n",
       "      <td>939.738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1654733338</td>\n",
       "      <td>20.103</td>\n",
       "      <td>53.20</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12439</td>\n",
       "      <td>19114</td>\n",
       "      <td>939.758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1654733339</td>\n",
       "      <td>20.117</td>\n",
       "      <td>52.81</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12448</td>\n",
       "      <td>19155</td>\n",
       "      <td>939.758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1654733340</td>\n",
       "      <td>20.132</td>\n",
       "      <td>52.46</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12453</td>\n",
       "      <td>19195</td>\n",
       "      <td>939.756</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.369</td>\n",
       "      <td>2.78</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         UTC  Temperature[C]  Humidity[%]  TVOC[ppb]  eCO2[ppm]  \\\n",
       "0           0  1654733331          20.000        57.36          0        400   \n",
       "1           1  1654733332          20.015        56.67          0        400   \n",
       "2           2  1654733333          20.029        55.96          0        400   \n",
       "3           3  1654733334          20.044        55.28          0        400   \n",
       "4           4  1654733335          20.059        54.69          0        400   \n",
       "5           5  1654733336          20.073        54.12          0        400   \n",
       "6           6  1654733337          20.088        53.61          0        400   \n",
       "7           7  1654733338          20.103        53.20          0        400   \n",
       "8           8  1654733339          20.117        52.81          0        400   \n",
       "9           9  1654733340          20.132        52.46          0        400   \n",
       "\n",
       "   Raw H2  Raw Ethanol  Pressure[hPa]  PM1.0  PM2.5  NC0.5  NC1.0  NC2.5  CNT  \\\n",
       "0   12306        18520        939.735    0.0   0.00    0.0  0.000   0.00    0   \n",
       "1   12345        18651        939.744    0.0   0.00    0.0  0.000   0.00    1   \n",
       "2   12374        18764        939.738    0.0   0.00    0.0  0.000   0.00    2   \n",
       "3   12390        18849        939.736    0.0   0.00    0.0  0.000   0.00    3   \n",
       "4   12403        18921        939.744    0.0   0.00    0.0  0.000   0.00    4   \n",
       "5   12419        18998        939.725    0.0   0.00    0.0  0.000   0.00    5   \n",
       "6   12432        19058        939.738    0.0   0.00    0.0  0.000   0.00    6   \n",
       "7   12439        19114        939.758    0.0   0.00    0.0  0.000   0.00    7   \n",
       "8   12448        19155        939.758    0.0   0.00    0.0  0.000   0.00    8   \n",
       "9   12453        19195        939.756    0.9   3.78    0.0  4.369   2.78    9   \n",
       "\n",
       "   Fire Alarm  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5           0  \n",
       "6           0  \n",
       "7           0  \n",
       "8           0  \n",
       "9           0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v.head(10)   #checking the top 10 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f641011",
   "metadata": {},
   "source": [
    "# REGARDING MISSING VALUES IT IS CLEAR IN \n",
    "# FILE:- class_3_partC_Data_Exploration_and_Proprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626f5de2",
   "metadata": {},
   "source": [
    "## Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4c9a33ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Temperatur_C        0\n",
       "Humidity_percent    0\n",
       "TVOC_ppd            0\n",
       "eCO2_ppm            0\n",
       "Raw_H2              0\n",
       "Raw_Ethanol         0\n",
       "Pressure_hpa        0\n",
       "PM1_0               0\n",
       "PM2_5               0\n",
       "NC0_5               0\n",
       "NC1_0               0\n",
       "NC2_5               0\n",
       "Fire_Alarm          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4970c6d5",
   "metadata": {},
   "source": [
    "## ADDING MISSING VALUES TO THE DATA\n",
    "\n",
    "### ADDING MISSING VALUES IN ONE COLUMN\n",
    "\n",
    "print(f\"Number of rows with valid BEDROOMS values before: {housing_df['BEDROOMS'].count()}\") \n",
    "\n",
    "add_missing_rows = housing_df.sample(10).index # create a random selection of rows that we will use as to overwrite with a NAN for BEDROOMS\n",
    "\n",
    "housing_df.loc[add_missing_rows, 'BEDROOMS'] = np.nan  # change these rows to have BEDROOM values NAN\n",
    "\n",
    "print(f\"Number of rows with valid BEDROOMS values after setting to NAN: {housing_df['BEDROOMS'].count()}\") \n",
    "\n",
    "\n",
    "## ADDING MISSING VALUES IN ONE ROW\n",
    "\n",
    "add_missing_values = housing_df.iloc[0:5,:].index # let's overwrite the first 10 rows with NAN's for bedrooms, fireplace and rooms\n",
    "\n",
    "housing_df.loc[add_missing_values, 'BEDROOMS'] = np.nan  # change these rows to have BEDROOM values NAN\n",
    "\n",
    "housing_df.loc[add_missing_values, 'FIREPLACE'] = np.nan  # change these rows to have BEDROOM values NAN\n",
    "\n",
    "housing_df.loc[add_missing_values, 'ROOMS'] = np.nan  # change these rows to have BEDROOM values NAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1805c16",
   "metadata": {},
   "source": [
    "### Replacing the null value with name\n",
    "\n",
    "data['OCCUPATION_TYPE'].fillna('Other',inplace=True)   # we are storing \"other\" in place of nulls\n",
    "\n",
    "syntax:\n",
    "dataframe['column name'].fillna('name',inplace=True)\n",
    "\n",
    "#if null vlaues are to be replaced with some name\n",
    "\n",
    "### Replcing the null value with average value\n",
    "data['OCCUPATION_TYPE'].fillna(mean(data['OCCUPATION_TYPE']),inplace=True)\n",
    "\n",
    "#replacing the null value with mean \n",
    "\n",
    "## Replacing the column name with other name\n",
    "wine_df.columns = ['od' if item == 'od280/od315_of_diluted_wines' else item for item in wine_df.columns]\n",
    "\n",
    "wine_df.head()\n",
    "\n",
    "## Impute / Replace Missing Values with Mean\n",
    "df.fillna(df.mean())\n",
    "\n",
    "## Impute / Replace Missing Values with Median\n",
    "df.fillna(df.median())\n",
    "\n",
    "OR\n",
    "\n",
    "\n",
    "medianBedrooms = housing_df['BEDROOMS'].median()\n",
    "housing_df.BEDROOMS = housing_df.BEDROOMS.fillna(value=medianBedrooms)\n",
    "print(f\"Number of rows with valid BEDROOMS values after filling NA values: {housing_df['BEDROOMS'].count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df80d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84edfb95",
   "metadata": {},
   "source": [
    "## DROPPING ROW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7862c38",
   "metadata": {},
   "source": [
    "### DROPPING ROW WITH MORE HAN THREE MISSING VALUES IN IT\n",
    "\n",
    "housing_df = housing_df[housing_df.isnull().sum(axis=1) < 3]\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0980b91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UTC</th>\n",
       "      <th>Temperature[C]</th>\n",
       "      <th>Humidity[%]</th>\n",
       "      <th>TVOC[ppb]</th>\n",
       "      <th>eCO2[ppm]</th>\n",
       "      <th>Raw H2</th>\n",
       "      <th>Raw Ethanol</th>\n",
       "      <th>Pressure[hPa]</th>\n",
       "      <th>PM1.0</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>NC0.5</th>\n",
       "      <th>NC1.0</th>\n",
       "      <th>NC2.5</th>\n",
       "      <th>CNT</th>\n",
       "      <th>Fire Alarm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1654733333</td>\n",
       "      <td>20.029</td>\n",
       "      <td>55.96</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12374</td>\n",
       "      <td>18764</td>\n",
       "      <td>939.738</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1654733334</td>\n",
       "      <td>20.044</td>\n",
       "      <td>55.28</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12390</td>\n",
       "      <td>18849</td>\n",
       "      <td>939.736</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1654733335</td>\n",
       "      <td>20.059</td>\n",
       "      <td>54.69</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12403</td>\n",
       "      <td>18921</td>\n",
       "      <td>939.744</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1654733336</td>\n",
       "      <td>20.073</td>\n",
       "      <td>54.12</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12419</td>\n",
       "      <td>18998</td>\n",
       "      <td>939.725</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1654733337</td>\n",
       "      <td>20.088</td>\n",
       "      <td>53.61</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12432</td>\n",
       "      <td>19058</td>\n",
       "      <td>939.738</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1654733338</td>\n",
       "      <td>20.103</td>\n",
       "      <td>53.20</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12439</td>\n",
       "      <td>19114</td>\n",
       "      <td>939.758</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1654733339</td>\n",
       "      <td>20.117</td>\n",
       "      <td>52.81</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12448</td>\n",
       "      <td>19155</td>\n",
       "      <td>939.758</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1654733340</td>\n",
       "      <td>20.132</td>\n",
       "      <td>52.46</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12453</td>\n",
       "      <td>19195</td>\n",
       "      <td>939.756</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.369</td>\n",
       "      <td>2.78</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1654733341</td>\n",
       "      <td>20.146</td>\n",
       "      <td>52.15</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12454</td>\n",
       "      <td>19230</td>\n",
       "      <td>939.757</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.289</td>\n",
       "      <td>2.73</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1654733342</td>\n",
       "      <td>20.161</td>\n",
       "      <td>51.84</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12467</td>\n",
       "      <td>19264</td>\n",
       "      <td>939.754</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.053</td>\n",
       "      <td>2.58</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0         UTC  Temperature[C]  Humidity[%]  TVOC[ppb]  eCO2[ppm]  \\\n",
       "2            2  1654733333          20.029        55.96          0        400   \n",
       "3            3  1654733334          20.044        55.28          0        400   \n",
       "4            4  1654733335          20.059        54.69          0        400   \n",
       "5            5  1654733336          20.073        54.12          0        400   \n",
       "6            6  1654733337          20.088        53.61          0        400   \n",
       "7            7  1654733338          20.103        53.20          0        400   \n",
       "8            8  1654733339          20.117        52.81          0        400   \n",
       "9            9  1654733340          20.132        52.46          0        400   \n",
       "10          10  1654733341          20.146        52.15          0        400   \n",
       "11          11  1654733342          20.161        51.84          0        400   \n",
       "\n",
       "    Raw H2  Raw Ethanol  Pressure[hPa]  PM1.0  PM2.5  NC0.5  NC1.0  NC2.5  \\\n",
       "2    12374        18764        939.738   0.00   0.00    0.0  0.000   0.00   \n",
       "3    12390        18849        939.736   0.00   0.00    0.0  0.000   0.00   \n",
       "4    12403        18921        939.744   0.00   0.00    0.0  0.000   0.00   \n",
       "5    12419        18998        939.725   0.00   0.00    0.0  0.000   0.00   \n",
       "6    12432        19058        939.738   0.00   0.00    0.0  0.000   0.00   \n",
       "7    12439        19114        939.758   0.00   0.00    0.0  0.000   0.00   \n",
       "8    12448        19155        939.758   0.00   0.00    0.0  0.000   0.00   \n",
       "9    12453        19195        939.756   0.90   3.78    0.0  4.369   2.78   \n",
       "10   12454        19230        939.757   0.89   3.71    0.0  4.289   2.73   \n",
       "11   12467        19264        939.754   0.84   3.51    0.0  4.053   2.58   \n",
       "\n",
       "    CNT  Fire Alarm  \n",
       "2     2           0  \n",
       "3     3           0  \n",
       "4     4           0  \n",
       "5     5           0  \n",
       "6     6           0  \n",
       "7     7           0  \n",
       "8     8           0  \n",
       "9     9           0  \n",
       "10   10           0  \n",
       "11   11           0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v.drop(df_v[(df_v['UTC']==1654733331) & (df_v['Temperature[C]'] ==20.00)].index, inplace=True)\n",
    "\n",
    "\n",
    "# dropping columns\n",
    "#eng_df.drop(columns=eng_df.iloc[:,:2].columns.tolist(), inplace=True)\n",
    "\n",
    "# dropping index\n",
    "df_v.drop(index=df_v.iloc[:1, :].index.tolist(), inplace=True)\n",
    "df_v.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf394aa",
   "metadata": {},
   "source": [
    "## DROPPING COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "76a02024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v=df_v.drop(columns=['Unnamed: 0','UTC','CNT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "afe259f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Temperature[C]', 'Humidity[%]', 'TVOC[ppb]', 'eCO2[ppm]', 'Raw H2',\n",
       "       'Raw Ethanol', 'Pressure[hPa]', 'PM1.0', 'PM2.5', 'NC0.5', 'NC1.0',\n",
       "       'NC2.5', 'Fire Alarm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919478d1",
   "metadata": {},
   "source": [
    "## Encoder (ordinal,label)\n",
    "\n",
    "\n",
    "enc = OrdinalEncoder(categories=[[' Male', ' Female']]) \n",
    "income_df.sex = enc.fit_transform(income_df[['sex']])\n",
    "income_df.head(5)\n",
    "\n",
    "\n",
    "NOTE: OrdinalEncoder will map the first value found to 0, then the next unique value found, 1, etc. If you wish to change, or control this order, you can speciy this in the categories parameter. For an OrdinalEncoder, since we can have multiple columns, we specify the categories for each column by creating a list of lists. In this specific case above, we only have one column we're encoding, therefore it's a list with one list inside.\n",
    "\n",
    "\n",
    "enc = LabelEncoder() income_df.income = enc.fit_transform(income_df['income']) income_df.head(5)\n",
    "\n",
    "\n",
    "## sample code for encoder for multiple columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "objectColumns = [\"CODE_GENDER\", \"FLAG_OWN_CAR\", \"FLAG_OWN_REALTY\", \"NAME_INCOME_TYPE\", \"NAME_EDUCATION_TYPE\", \"NAME_FAMILY_STATUS\", \"NAME_HOUSING_TYPE\",\n",
    "                \"OCCUPATION_TYPE\"]\n",
    "                \n",
    "for objColumn in objectColumns:\n",
    "    label = LabelEncoder()\n",
    "    data[objColumn] = label.fit_transform(data[objColumn].values)\n",
    "    \n",
    "    \n",
    "## DUMMY ENCODING\n",
    "\n",
    "We need to first chage the variable into categorical and then do the encoding\n",
    "\n",
    "new_df = pd.get_dummies(new_df, prefix_sep='_')\n",
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8408d04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v['Fire Alarm'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "85d339cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62628 entries, 2 to 62629\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Temperature[C]  62628 non-null  float64\n",
      " 1   Humidity[%]     62628 non-null  float64\n",
      " 2   TVOC[ppb]       62628 non-null  int64  \n",
      " 3   eCO2[ppm]       62628 non-null  int64  \n",
      " 4   Raw H2          62628 non-null  int64  \n",
      " 5   Raw Ethanol     62628 non-null  int64  \n",
      " 6   Pressure[hPa]   62628 non-null  float64\n",
      " 7   PM1.0           62628 non-null  float64\n",
      " 8   PM2.5           62628 non-null  float64\n",
      " 9   NC0.5           62628 non-null  float64\n",
      " 10  NC1.0           62628 non-null  float64\n",
      " 11  NC2.5           62628 non-null  float64\n",
      " 12  Fire Alarm      62628 non-null  int64  \n",
      "dtypes: float64(8), int64(5)\n",
      "memory usage: 6.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_v.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fbc36a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature[C]</th>\n",
       "      <th>Humidity[%]</th>\n",
       "      <th>TVOC[ppb]</th>\n",
       "      <th>eCO2[ppm]</th>\n",
       "      <th>Raw H2</th>\n",
       "      <th>Raw Ethanol</th>\n",
       "      <th>Pressure[hPa]</th>\n",
       "      <th>PM1.0</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>NC0.5</th>\n",
       "      <th>NC1.0</th>\n",
       "      <th>NC2.5</th>\n",
       "      <th>Fire Alarm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62628.000000</td>\n",
       "      <td>62628.000000</td>\n",
       "      <td>62628.000000</td>\n",
       "      <td>62628.000000</td>\n",
       "      <td>62628.000000</td>\n",
       "      <td>62628.000000</td>\n",
       "      <td>62628.000000</td>\n",
       "      <td>62628.000000</td>\n",
       "      <td>62628.000000</td>\n",
       "      <td>62628.000000</td>\n",
       "      <td>62628.000000</td>\n",
       "      <td>62628.000000</td>\n",
       "      <td>62628.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.970295</td>\n",
       "      <td>48.539229</td>\n",
       "      <td>1942.119547</td>\n",
       "      <td>670.029667</td>\n",
       "      <td>12942.473638</td>\n",
       "      <td>19754.295235</td>\n",
       "      <td>938.627614</td>\n",
       "      <td>100.597522</td>\n",
       "      <td>184.473661</td>\n",
       "      <td>491.479302</td>\n",
       "      <td>203.592989</td>\n",
       "      <td>80.051599</td>\n",
       "      <td>0.714648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.359787</td>\n",
       "      <td>8.865379</td>\n",
       "      <td>7811.706077</td>\n",
       "      <td>1905.915261</td>\n",
       "      <td>272.446326</td>\n",
       "      <td>609.486990</td>\n",
       "      <td>1.331350</td>\n",
       "      <td>922.538800</td>\n",
       "      <td>1976.336896</td>\n",
       "      <td>4265.728459</td>\n",
       "      <td>2214.773620</td>\n",
       "      <td>1083.400393</td>\n",
       "      <td>0.451585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-22.010000</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>10668.000000</td>\n",
       "      <td>15317.000000</td>\n",
       "      <td>930.852000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.994000</td>\n",
       "      <td>47.530000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>12830.000000</td>\n",
       "      <td>19435.000000</td>\n",
       "      <td>938.700000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>1.340000</td>\n",
       "      <td>8.820000</td>\n",
       "      <td>1.384000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.130000</td>\n",
       "      <td>50.150000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>12924.000000</td>\n",
       "      <td>19501.000000</td>\n",
       "      <td>938.816000</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>12.450000</td>\n",
       "      <td>1.943000</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.410000</td>\n",
       "      <td>53.240000</td>\n",
       "      <td>1189.000000</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>13109.000000</td>\n",
       "      <td>20078.000000</td>\n",
       "      <td>939.418000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>14.420000</td>\n",
       "      <td>2.249000</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.930000</td>\n",
       "      <td>75.200000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>13803.000000</td>\n",
       "      <td>21410.000000</td>\n",
       "      <td>939.861000</td>\n",
       "      <td>14333.690000</td>\n",
       "      <td>45432.260000</td>\n",
       "      <td>61482.030000</td>\n",
       "      <td>51914.680000</td>\n",
       "      <td>30026.438000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature[C]   Humidity[%]     TVOC[ppb]     eCO2[ppm]        Raw H2  \\\n",
       "count    62628.000000  62628.000000  62628.000000  62628.000000  62628.000000   \n",
       "mean        15.970295     48.539229   1942.119547    670.029667  12942.473638   \n",
       "std         14.359787      8.865379   7811.706077   1905.915261    272.446326   \n",
       "min        -22.010000     10.740000      0.000000    400.000000  10668.000000   \n",
       "25%         10.994000     47.530000    130.000000    400.000000  12830.000000   \n",
       "50%         20.130000     50.150000    981.000000    400.000000  12924.000000   \n",
       "75%         25.410000     53.240000   1189.000000    438.000000  13109.000000   \n",
       "max         59.930000     75.200000  60000.000000  60000.000000  13803.000000   \n",
       "\n",
       "        Raw Ethanol  Pressure[hPa]         PM1.0         PM2.5         NC0.5  \\\n",
       "count  62628.000000   62628.000000  62628.000000  62628.000000  62628.000000   \n",
       "mean   19754.295235     938.627614    100.597522    184.473661    491.479302   \n",
       "std      609.486990       1.331350    922.538800   1976.336896   4265.728459   \n",
       "min    15317.000000     930.852000      0.000000      0.000000      0.000000   \n",
       "25%    19435.000000     938.700000      1.280000      1.340000      8.820000   \n",
       "50%    19501.000000     938.816000      1.810000      1.880000     12.450000   \n",
       "75%    20078.000000     939.418000      2.090000      2.180000     14.420000   \n",
       "max    21410.000000     939.861000  14333.690000  45432.260000  61482.030000   \n",
       "\n",
       "              NC1.0         NC2.5    Fire Alarm  \n",
       "count  62628.000000  62628.000000  62628.000000  \n",
       "mean     203.592989     80.051599      0.714648  \n",
       "std     2214.773620   1083.400393      0.451585  \n",
       "min        0.000000      0.000000      0.000000  \n",
       "25%        1.384000      0.033000      0.000000  \n",
       "50%        1.943000      0.044000      1.000000  \n",
       "75%        2.249000      0.051000      1.000000  \n",
       "max    51914.680000  30026.438000      1.000000  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9df699",
   "metadata": {},
   "source": [
    "## Changing the names of the data for better use in future code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bb961aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Temperatur_C', 'Humidity_percent', 'TVOC_ppd', 'eCO2_ppm', 'Raw_H2',\n",
       "       'Raw_Ethanol', 'Pressure_hpa', 'PM1_0', 'PM2_5', 'NC0_5', 'NC1_0',\n",
       "       'NC2_5', 'Fire_Alarm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v.columns = [s.strip().replace(' ', '_') for s in df_v.columns] #basic\n",
    "df_v.columns = [s.strip().replace('.', '_') for s in df_v.columns] \n",
    "df_v.columns=[s.strip().replace('Temperature[C]','Temperatur_C') for s in df_v.columns]\n",
    "df_v.columns=[s.strip().replace('TVOC[ppb]','TVOC_ppd') for s in df_v.columns]\n",
    "df_v.columns=[s.strip().replace('eCO2[ppm]','eCO2_ppm') for s in df_v.columns]\n",
    "df_v.columns=[s.strip().replace('Pressure[hPa]','Pressure_hpa') for s in df_v.columns]\n",
    "df_v.columns=[s.strip().replace('Humidity[%]','Humidity_percent') for s in df_v.columns]\n",
    "\n",
    "df_v.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0543ae01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]\n",
       "Categories (2, int64): [0, 1]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v.Fire_Alarm=df_v.Fire_Alarm.astype(\"category\")\n",
    "df_v.Fire_Alarm.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e41c1a",
   "metadata": {},
   "source": [
    "## Splitting the data into 70-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "878e7f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df=train_test_split(df_v,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b176c55f",
   "metadata": {},
   "source": [
    "## OVERSAMPLING TO ADRESS THE DATA IMBALANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "35112844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    31330\n",
       "1    31330\n",
       "Name: Fire_Alarm, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_count = (train_df.Fire_Alarm==1).sum()\n",
    "nf_count = (train_df.Fire_Alarm==0).sum()\n",
    "\n",
    "nf_df  = train_df.loc[train_df.Fire_Alarm==0]\n",
    "df_oversampled = nf_df.sample(n=f_count-nf_count,replace=True)\n",
    "\n",
    "train_df = pd.concat([train_df, df_oversampled], ignore_index=True)\n",
    "train_df.Fire_Alarm.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4997a84",
   "metadata": {},
   "source": [
    "## Rescale data (k-NN is particularly sensitive to distances in scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7337158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reduce repetition in later code, create variables to represent the columns\n",
    "# that are our predictors and target\n",
    "target = 'Fire_Alarm'\n",
    "predictors = list(df_v.columns)\n",
    "predictors.remove(target)\n",
    "\n",
    "# create a standard scaler and fit it to the training set of predictors\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df[predictors])\n",
    "\n",
    "# Transform the predictors of training and validation sets\n",
    "X_train = scaler.transform(train_df[predictors]) # train_predictors is not a numpy array\n",
    "y_train = train_df[target] # train_target is now a series object\n",
    "\n",
    "X_test = scaler.transform(test_df[predictors]) # validation_target is now a series object\n",
    "y_test = test_df[target] # validation_target is now a series object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "79cc1d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df.drop(columns=['Fire_Alarm'])\n",
    "y_train =train_df.Fire_Alarm\n",
    "X_test =  test_df.drop(columns=['Fire_Alarm'])\n",
    "y_test = test_df.Fire_Alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf466db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a34880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53f30ebb",
   "metadata": {},
   "source": [
    "## NORMALIZING \n",
    "Normalization is a good technique to use when you do not know the distribution of your data or when you know the distribution is not Gaussian (a bell curve). Normalization is useful when your data has varying scales and the algorithm you are using does not make assumptions about the distribution of your data, such as k-nearest neighbors and artificial neural networks.\n",
    "\n",
    "method:1:\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler() \n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "method:2:\n",
    "mower_df[['Income', 'Lot_Size']] = mower_df[['Income', 'Lot_Size']].apply(lambda iterator: ((iterator - iterator.mean())/iterator.std()).round(2))\n",
    "\n",
    "\n",
    "In this approach, the data is scaled to a fixed range — usually 0 to 1.\n",
    "In contrast to standardization, the cost of having this bounded range is that we will end up with smaller standard deviations, which can suppress the effect of outliers. Thus MinMax Scalar is sensitive to outliers.\n",
    "\n",
    "After MinMaxScaling, the distributions are not centered at zero and the standard deviation is not 1.\n",
    "But the minimum and maximum values are standardized across variables, different from what occurs with standardization.\n",
    "\n",
    "\n",
    "## Rescaling the Data\n",
    "\n",
    "normalization is the method of rescaling data where we try to fit all the data points between the range of 0 to 1 so that the data points can become closer to each other. It is a very common approach to scaling the data.\n",
    "\n",
    "## Standardizing\n",
    "\n",
    "standardization (or Z-score normalization) means centering the variable at zero and standardizing the variance at 1.The procedure involves subtracting the mean of each observation and then dividing by the standard deviation.\n",
    "\n",
    "method:1  :\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "\n",
    "As expected, the mean of each variable is now around zero and the standard deviation is set to 1. Thus, all the variable values lie within the same range.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## GENERILIZED METHOD USED BY SIR IN ALL PROBLEMS\n",
    "\n",
    "K-nn models are sensitive to differences in scale; therefore, we should begin by eliminating any differences in scale between the predictors/features. To accomplish this, we will standardize the values of each variable.\n",
    "\n",
    "We will use the popular sklearn library's 'standard scaler' to accomplish this. This library contains many of the common functions we require when conducting analytics. The standard scaler function will standardize our variables. To achieve this, we will first need to train the scaler on the training data and then apply this trained scaler to standardize both the training and validation sets.\n",
    "\n",
    "#### create a standard scaler and fit it to the training set of predictors\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_df[predictors])\n",
    "\n",
    "#### Transform the predictors of training and validation sets\n",
    "train_predictors = scaler.transform(train_df[predictors]) # train_predictors is not a numpy array\n",
    "train_target = train_df[target] # train_target is now a series object\n",
    "\n",
    "validation_predictors = scaler.transform(validation_df[predictors]) # validation_target is now a series object\n",
    "validation_target = validation_df[target] # validation_target is now a series object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ee0acb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a standard scaler and fit it to the training set of predictors\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X_train)\n",
    "\n",
    "# Transform the predictors of both the training and validation sets\n",
    "#X_train = scaler.transform(X_train) \n",
    "#X_test = scaler.transform(X_test) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfc0da1",
   "metadata": {},
   "source": [
    "## NORMAL KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ed398225",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=251,  metric='euclidean') # user euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fd8d8b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "knn_prediction_output = knn.predict(X_test)\n",
    "knn_prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "09e92a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5346,    16],\n",
       "       [   31, 13396]], dtype=int64)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, knn_prediction_output)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9157af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1, 1] # True Positives\n",
    "TN = confusion[0, 0] # True Negatives\n",
    "FP = confusion[0, 1] # False Positives\n",
    "FN = confusion[1, 0] # False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "39b0e80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9975\n",
      "0.9988\n",
      "0.9977\n",
      "0.9982\n"
     ]
    }
   ],
   "source": [
    "classification_accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(f\"{classification_accuracy:.4f}\")\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "print(f\"{precision:.4f}\")\n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "print(f\"{recall:.4f}\")\n",
    "\n",
    "f1_Score = (2 * precision * recall) / (precision + recall)\n",
    "print(f\"{f1_Score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a8daf4",
   "metadata": {},
   "source": [
    "## BEST K VALUE(TESTING KNN AT DIFFERENT VALUES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "faaa7a8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [149]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     knn \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39mk,  metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m     knn\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m----> 5\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend ({\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m: k,\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: accuracy_score(y_test, y_pred),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m: f1_score(y_test, y_pred)\n\u001b[0;32m     12\u001b[0m     })\n\u001b[0;32m     14\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:226\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py:814\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m    809\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    810\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not work with sparse matrices. Densify the data, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    811\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor set algorithm=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    812\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method\n\u001b[0;32m    813\u001b[0m         )\n\u001b[1;32m--> 814\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_tree_query_parallel_helper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    816\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\n\u001b[0;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    818\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    819\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternal: _fit_method not recognized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py:623\u001b[0m, in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tree_query_parallel_helper\u001b[39m(tree, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;124;03m\"\"\"Helper for the Parallel calls in KNeighborsMixin.kneighbors.\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \n\u001b[0;32m    620\u001b[0m \u001b[38;5;124;03m    The Cython method tree.query is not directly picklable by cloudpickle\u001b[39;00m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;124;03m    under PyPy.\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for k in range(1,int(len(y_train)**0.5),2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k,  metric='euclidean')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    results.append ({\n",
    "        'k': k,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b9585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[[results_df.accuracy.idxmax()]]\n",
    "results_df.loc[[results_df.precision.idxmax()]]\n",
    "results_df.loc[[results_df.recall.idxmax()]]\n",
    "results_df.loc[[results_df.f1.idxmax()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f0029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "820688e6",
   "metadata": {},
   "source": [
    "## KNN WITH KFOLD USING GRIDSEARCH CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c7cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR F1 SCORE\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "k_range = list(range(1, 251))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "  \n",
    "# defining parameter range\n",
    "grid = GridSearchCV(knn, param_grid, cv=5, scoring='f1', return_train_score=False,verbose=1)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid_search=grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#BEST PARAMETER\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "\n",
    "#BEST F1 SCORE\n",
    "f1 = grid_search.best_score_ *100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a214677",
   "metadata": {},
   "source": [
    "## DECISION TREE NORMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ab853317",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree=DecisionTreeClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "10967591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=1)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "943271fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "  [[ 5359     3]\n",
      " [    0 13427]]\n",
      "Accuracy score:\n",
      " 0.9998403321092129\n",
      "Precision score:\n",
      " 0.9997766195085629\n",
      "Recall score:\n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "# checking the performance of decision tree on test data\n",
    "\n",
    "validation_predictions = dtree.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix:\\n ', confusion_matrix(y_test, validation_predictions))\n",
    "print('Accuracy score:\\n', accuracy_score(y_test, validation_predictions))\n",
    "print('Precision score:\\n', precision_score(y_test, validation_predictions))\n",
    "print('Recall score:\\n', recall_score(y_test, validation_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "585d7b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.9998403321092129\n",
      "Precision= 0.9997766195085629\n",
      "Recall= 1.0\n",
      "f1= 0.999888297278177\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy=\", accuracy_score(y_test, dtree.predict(X_test)))\n",
    "print(f\"Precision=\", precision_score(y_test, dtree.predict(X_test)))\n",
    "print(f\"Recall=\", recall_score(y_test, dtree.predict(X_test)))      \n",
    "print(f\"f1=\", f1_score(y_test, dtree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb983e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d1698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72827044",
   "metadata": {},
   "source": [
    "## DECISION TREE WITH TUNNING USING GRID SEARCH CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b06ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = 'precision'\n",
    "k_fold = 10\n",
    "# Start with an initial guess for parameters\n",
    "param_grid = {\n",
    "    'max_depth': [2, 5, 10, 20, 30, 40], \n",
    "    'min_samples_split': [2, 5, 10, 20, 40, 60, 80, 100], \n",
    "    'min_impurity_decrease': [0, 0.0005, 0.001, 0.005, 0.01], \n",
    "}\n",
    "gridSearch = GridSearchCV(DecisionTreeClassifier(random_state=1), param_grid, cv=k_fold, scoring=score_measure,\n",
    "                          n_jobs=-1)  # n_jobs=-1 will utilize all available CPUs \n",
    "gridSearch.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', gridSearch.best_score_)\n",
    "print('parameters: ', gridSearch.best_params_)\n",
    "\n",
    "bestPrecisionTree = gridSearch.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8705ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = 'recall'\n",
    "k_fold = 10\n",
    "# Start with an initial guess for parameters\n",
    "param_grid = {\n",
    "    'max_depth': [2, 5, 10, 20, 30, 40], \n",
    "    'min_samples_split': [2, 5, 10, 20, 40, 60, 80, 100], \n",
    "    'min_impurity_decrease': [0, 0.0005, 0.001, 0.005, 0.01], \n",
    "}\n",
    "gridSearch = GridSearchCV(DecisionTreeClassifier(random_state=1), param_grid, cv=k_fold, scoring=score_measure,\n",
    "                          n_jobs=-1)  # n_jobs=-1 will utilize all available CPUs \n",
    "gridSearch.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', gridSearch.best_score_)\n",
    "print('parameters: ', gridSearch.best_params_)\n",
    "\n",
    "bestRecallTree = gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = 'accuracy'\n",
    "k_fold = 10\n",
    "# Start with an initial guess for parameters\n",
    "param_grid = {\n",
    "    'max_depth': [2, 5, 10, 20, 30, 40], \n",
    "    'min_samples_split': [2, 5, 10, 20, 40, 60, 80, 100], \n",
    "    'min_impurity_decrease': [0, 0.0005, 0.001, 0.005, 0.01], \n",
    "}\n",
    "gridSearch = GridSearchCV(DecisionTreeClassifier(random_state=1), param_grid, cv=k_fold, scoring=score_measure,\n",
    "                          n_jobs=-1)  # n_jobs=-1 will utilize all available CPUs \n",
    "gridSearch.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', gridSearch.best_score_)\n",
    "print('parameters: ', gridSearch.best_params_)\n",
    "\n",
    "bestAccuracyTree = gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06780627",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = 'f1'\n",
    "k_fold = 10\n",
    "# Start with an initial guess for parameters\n",
    "param_grid = {\n",
    "    'max_depth': [2, 5, 10, 20, 30, 40], \n",
    "    'min_samples_split': [2, 5, 10, 20, 40, 60, 80, 100], \n",
    "    'min_impurity_decrease': [0, 0.0005, 0.001, 0.005, 0.01], \n",
    "}\n",
    "gridSearch = GridSearchCV(DecisionTreeClassifier(random_state=1), param_grid, cv=k_fold, scoring=score_measure,\n",
    "                          n_jobs=-1)  # n_jobs=-1 will utilize all available CPUs \n",
    "gridSearch.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', gridSearch.best_score_)\n",
    "print('parameters: ', gridSearch.best_params_)\n",
    "\n",
    "bestf1Tree = gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f412de",
   "metadata": {},
   "source": [
    "## DECISION TREE WITH TUNNING USING RANDOM SEARCH CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e94c87f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion used to guide data splits\n",
    "criterion = ['gini', 'entropy', 'log_loss']\n",
    "\n",
    "# Maximum number of levels in tree. If None, then nodes are expanded until all leaves are pure or until all \n",
    "# leaves contain less than min_samples_split samples.\n",
    "# default = None\n",
    "max_depth = [int(x) for x in np.linspace(1, 40000, 50)]\n",
    "\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "# default is 2\n",
    "min_samples_split = [int(x) for x in np.linspace(2, 5000, 50)]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "# default = 1 \n",
    "min_samples_leaf = [int(x) for x in np.linspace(1, 10000, 50)]\n",
    "\n",
    "# max_leaf_nodes  - Grow trees with max_leaf_nodes in best-first fashion.\n",
    "# If None then unlimited number of leaf nodes.\n",
    "# default=None \n",
    "max_leaf_nodes = [int(x) for x in np.linspace(2, len(y_test), 50)]\n",
    "\n",
    "\n",
    "# min_impurity_decrease - A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "# default=0.0\n",
    "min_impurity_decrease = [x for x in np.arange(0.0, 0.01, 0.0001).round(5)]\n",
    "\n",
    "# Create the random grid\n",
    "param_grid_random = { 'criterion': criterion,\n",
    "                      'max_depth': max_depth,\n",
    "                      'min_samples_split': min_samples_split,\n",
    "                      'min_samples_leaf' : min_samples_leaf,\n",
    "                      'max_leaf_nodes' : max_leaf_nodes,\n",
    "                      'min_impurity_decrease' : min_impurity_decrease,\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810e5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_default = DecisionTreeClassifier(random_state=1)\n",
    "# change n_iter to 200_000 for full run\n",
    "best_random_search_model = RandomizedSearchCV(\n",
    "        estimator=DecisionTreeClassifier(random_state=1),  \n",
    "        \n",
    "        param_distributions=param_grid_random, \n",
    "        n_iter = 5_000, \n",
    "        cv=10, \n",
    "        verbose=0, \n",
    "        n_jobs = -1\n",
    "    )\n",
    "best_random_search_model = best_random_search_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1d1402",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_best_params = best_random_search_model.best_params_\n",
    "print('Best parameters found: ', random_search_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_random_search_model.predict(valid_X)\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred,average='weighted')}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred,average='weighted')}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred,average='weighted')}\")\n",
    "print(\"************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e65d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58c5345a",
   "metadata": {},
   "source": [
    "## RANDOM FOREST NORMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2e10fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest = RandomForestClassifier(random_state=random_seed)\n",
    "_ = rforest.fit(X_train, y_train)\n",
    "y_pred = rforest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f9505d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  1.0\n",
      "Accuracy Score:   0.9999467773697376\n",
      "Precision Score:  0.9999255287459041\n",
      "F1 Score:         0.9999627629864085\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501f68b",
   "metadata": {},
   "source": [
    "## Prediction with ADABoost (using default parameters)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "926846cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "aboost = AdaBoostClassifier(random_state=random_seed)\n",
    "_ = aboost.fit(X_train, y_train)\n",
    "y_pred = aboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "11581d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.9996276159976167\n",
      "Accuracy Score:   0.9994145510671137\n",
      "Precision Score:  0.9995531724754245\n",
      "F1 Score:         0.9995903928504934\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0214cbe",
   "metadata": {},
   "source": [
    "## Prediction with GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e5bcc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingClassifier(random_state=random_seed)\n",
    "_ = gboost.fit(X_train, y_train)\n",
    "y_pred = gboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3cb2e81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.9999255231995233\n",
      "Accuracy Score:   0.9998935547394753\n",
      "Precision Score:  0.9999255231995233\n",
      "F1 Score:         0.9999255231995233\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1f3a2b",
   "metadata": {},
   "source": [
    "## Prediction with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4d1eb7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier(random_state=random_seed)\n",
    "_ = xgboost.fit(X_train, y_train)\n",
    "y_pred = xgboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7fddcfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  1.0\n",
      "Accuracy Score:   0.9998403321092129\n",
      "Precision Score:  0.9997766195085629\n",
      "F1 Score:         0.999888297278177\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42abc33",
   "metadata": {},
   "source": [
    "## Machine learning classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3119cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train, y_train)\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bdbf360a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [173]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m(y_test, y_pred))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d8b132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
